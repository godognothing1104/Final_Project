{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "#import libraries\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageGrab"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " # Randomly initialises values of thetas between [-epsilon, +epsilon]\n",
    "def initialise(a, b):\n",
    "    epsilon = 0.15\n",
    "    c = np.random.rand(a, b + 1) * (2 * epsilon) -epsilon  \n",
    "    return c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T12:32:06.416078Z",
     "start_time": "2024-12-05T12:32:06.410190Z"
    }
   },
   "id": "6e4a5693c036b6b",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function performs feed-forward and backpropagation. \n",
    "\n",
    "Forward propagation: Input data is fed in the forward direction through the network. Each hidden layer accepts the input data, processes it as per the activation function and passes it to the successive layer. We will use the sigmoid function as our “activation function”.\n",
    "Backward propagation: It is the practice of fine-tuning the weights of a neural net based on the error rate obtained in the previous iteration.\n",
    "It also calculates cross-entropy costs for checking the errors between the prediction and original values. In the end, the gradient is calculated for the optimization objective.   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aca847eadffb249"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def neural_network(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lamb):\n",
    "    # Weights are split back to Theta1, Theta2\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, input_layer_size + 1))\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \n",
    "                        (num_labels, hidden_layer_size + 1))\n",
    "\n",
    "    # Forward propagation\n",
    "    m = X.shape[0]\n",
    "    one_matrix = np.ones((m, 1))\n",
    "    X = np.append(one_matrix, X, axis=1)  # Adding bias unit to first layer\n",
    "    a1 = X\n",
    "    z2 = np.dot(X, Theta1.transpose())\n",
    "    a2 = 1 / (1 + np.exp(-z2))  # Activation for second layer\n",
    "    one_matrix = np.ones((m, 1))\n",
    "    a2 = np.append(one_matrix, a2, axis=1)  # Adding bias unit to hidden layer\n",
    "    z3 = np.dot(a2, Theta2.transpose())\n",
    "    a3 = 1 / (1 + np.exp(-z3))  # Activation for third layer\n",
    "\n",
    "    # Changing the y labels into vectors of boolean values.\n",
    "    # For each label between 0 and 9, there will be a vector of length 10\n",
    "    # where the ith element will be 1 if the label equals i\n",
    "    y_vect = np.zeros((m, 10))\n",
    "    for i in range(m):\n",
    "        y_vect[i, int(y[i])] = 1\n",
    "\n",
    "    # Calculating cost function\n",
    "    J = (1 / m) * (np.sum(np.sum(-y_vect * np.log(a3) - (1 - y_vect) * np.log(1 - a3)))) + (lamb / (2 * m)) * (\n",
    "                sum(sum(pow(Theta1[:, 1:], 2))) + sum(sum(pow(Theta2[:, 1:], 2))))\n",
    "\n",
    "    # backprop\n",
    "    Delta3 = a3 - y_vect\n",
    "    Delta2 = np.dot(Delta3, Theta2) * a2 * (1 - a2)\n",
    "    Delta2 = Delta2[:, 1:]\n",
    "\n",
    "    # gradient\n",
    "    Theta1[:, 0] = 0\n",
    "    Theta1_grad = (1 / m) * np.dot(Delta2.transpose(), a1) + (lamb / m) * Theta1\n",
    "    Theta2[:, 0] = 0\n",
    "    Theta2_grad = (1 / m) * np.dot(Delta3.transpose(), a2) + (lamb / m) * Theta2\n",
    "    grad = np.concatenate((Theta1_grad.flatten(), Theta2_grad.flatten()))\n",
    "\n",
    "    return J, grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T12:32:06.449323Z",
     "start_time": "2024-12-05T12:32:06.441084Z"
    }
   },
   "id": "6dcca555a3561f3a",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "It performs forward propagation to predict the digit."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59cf4f39ed645b5d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    m = X.shape[0]\n",
    "    one_matrix = np.ones((m, 1))\n",
    "    X = np.append(one_matrix, X, axis=1)  # Adding bias unit to first layer\n",
    "    z2 = np.dot(X, Theta1.transpose())\n",
    "    a2 = 1 / (1 + np.exp(-z2))  # Activation for second layer\n",
    "    one_matrix = np.ones((m, 1))\n",
    "    a2 = np.append(one_matrix, a2, axis=1)  # Adding bias unit to hidden layer\n",
    "    z3 = np.dot(a2, Theta2.transpose())\n",
    "    a3 = 1 / (1 + np.exp(-z3))  # Activation for third layer\n",
    "    p = (np.argmax(a3, axis=1))  # Predicting the class on the basis of max value of hypothesis\n",
    "    return p"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T12:32:06.478156Z",
     "start_time": "2024-12-05T12:32:06.472330Z"
    }
   },
   "id": "81cde4382e87c099",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing all the required libraries, extract the data from mnist-original.mat file. Then features and labels will be separated from extracted data. After that data will be split into training (60,000) and testing (10,000) examples. Randomly initialize Thetas in the range of [-0.15, +0.15] to break symmetry and get better results. Further, the optimizer is called for the training of weights, to minimize the cost function for appropriate predictions. We have used the “minimize” optimizer from “scipy.optimize” library with “L-BFGS-B” method. We have calculated the test, the “training set accuracy and precision using “predict” function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2e5eabbe2b82d96"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 97.540000\n",
      "Training Set Accuracy: 99.535000\n",
      "Precision = 0.99535\n"
     ]
    }
   ],
   "source": [
    "# Loading mat file\n",
    "data = loadmat('mnist-original.mat')\n",
    "\n",
    "# Extracting features from mat file\n",
    "X = data['data']\n",
    "X = X.transpose()\n",
    "\n",
    "# Normalizing the data\n",
    "X = X / 255\n",
    "\n",
    "# Extracting labels from mat file\n",
    "y = data['label']\n",
    "y = y.flatten()\n",
    "\n",
    "# Splitting data into training set with 60,000 examples\n",
    "X_train = X[:60000, :]\n",
    "y_train = y[:60000]\n",
    "\n",
    "# Splitting data into testing set with 10,000 examples\n",
    "X_test = X[60000:, :]\n",
    "y_test = y[60000:]\n",
    "\n",
    "m = X.shape[0]\n",
    "input_layer_size = 784  # Images are of (28 X 28) px so there will be 784 features\n",
    "hidden_layer_size = 100\n",
    "num_labels = 10  # There are 10 classes [0, 9]\n",
    "\n",
    "# Randomly initialising Thetas\n",
    "initial_Theta1 = initialise(hidden_layer_size, input_layer_size)\n",
    "initial_Theta2 = initialise(num_labels, hidden_layer_size)\n",
    "\n",
    "# Unrolling parameters into a single column vector\n",
    "initial_nn_params = np.concatenate((initial_Theta1.flatten(), initial_Theta2.flatten()))\n",
    "maxiter = 100\n",
    "lambda_reg = 0.1  # To avoid overfitting\n",
    "myargs = (input_layer_size, hidden_layer_size, num_labels, X_train, y_train, lambda_reg)\n",
    "\n",
    "# Calling minimize function to minimize cost function and to train weights\n",
    "results = minimize(neural_network, x0=initial_nn_params, args=myargs, \n",
    "          options={'disp': True, 'maxiter': maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "nn_params = results[\"x\"]  # Trained Theta is extracted\n",
    "\n",
    "# Weights are split back to Theta1, Theta2\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], (\n",
    "                              hidden_layer_size, input_layer_size + 1))  # shape = (100, 785)\n",
    "Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \n",
    "                      (num_labels, hidden_layer_size + 1))  # shape = (10, 101)\n",
    "\n",
    "# Checking test set accuracy of our model\n",
    "pred = predict(Theta1, Theta2, X_test)\n",
    "print('Test Set Accuracy: {:f}'.format((np.mean(pred == y_test) * 100)))\n",
    "\n",
    "# Checking train set accuracy of our model\n",
    "pred = predict(Theta1, Theta2, X_train)\n",
    "print('Training Set Accuracy: {:f}'.format((np.mean(pred == y_train) * 100)))\n",
    "\n",
    "# Evaluating precision of our model\n",
    "true_positive = 0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == y_train[i]:\n",
    "        true_positive += 1\n",
    "false_positive = len(y_train) - true_positive\n",
    "print('Precision =', true_positive/(true_positive + false_positive))\n",
    "\n",
    "# Saving Thetas in .txt file\n",
    "np.savetxt('Theta1.txt', Theta1, delimiter=' ')\n",
    "np.savetxt('Theta2.txt', Theta2, delimiter=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T12:34:16.357270Z",
     "start_time": "2024-12-05T12:32:06.503167Z"
    }
   },
   "id": "496ce705a1f5c89a",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "It launches a GUI for writing digits. The image of the digit is stored in the same directory after converting it to grayscale and reducing the size to (28 X 28) pixels. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b332bdca2be8ff47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window = Tk()\n",
    "window.title(\"Handwritten Digit Recognition(Inspired by LeCun's Work)\")\n",
    "l1 = Label()\n",
    "drawing_image = Image.new(\"L\", (350, 290), \"black\")\n",
    "draw = ImageDraw.Draw(drawing_image)\n",
    "\n",
    "predictions = []\n",
    "timestamps = []\n",
    "mock_history = {\n",
    "    'accuracy': [0.85, 0.88, 0.90, 0.92, 0.93],\n",
    "    'val_accuracy': [0.82, 0.85, 0.87, 0.89, 0.91]\n",
    "}\n",
    "\n",
    "# Function to display the grayscale image\n",
    "def show_grayscale_image(image):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.title(\"Input Grayscale Image\")\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Function to visualize weights (optional, if weights are small matrices)\n",
    "def visualize_weights(weights, title=\"Theta Visualization\"):\n",
    "    num_weights = weights.shape[0]\n",
    "    fig, axs = plt.subplots(1, num_weights, figsize=(15, 5))\n",
    "    for i in range(num_weights):\n",
    "        axs[i].imshow(weights[i].reshape(28, 28), cmap='gray')\n",
    "        axs[i].set_title(f\"Weight {i + 1}\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def show_accuracy_table(pred_probs):\n",
    "    # Create a new window for the table\n",
    "    table_window = Toplevel(window)\n",
    "    table_window.title(\"Prediction Accuracy Table\")\n",
    "    \n",
    "    # Create a treeview for the table\n",
    "    tree = ttk.Treeview(table_window, columns=('Digit', 'Confidence'), show='headings')\n",
    "    tree.heading('Digit', text='Digit')\n",
    "    tree.heading('Confidence', text='Confidence (%)')\n",
    "    tree.grid(row=0, column=0, padx=10, pady=10)\n",
    "    \n",
    "    # Populate the table with prediction probabilities\n",
    "    for i, prob in enumerate(pred_probs.flatten()):  # Ensure 1D array\n",
    "        tree.insert('', 'end', values=(i, f\"{float(prob) * 100:.2f}\"))\n",
    "\n",
    "    # Add a button to close the table\n",
    "    close_button = Button(table_window, text=\"Close\", command=table_window.destroy, bg=\"red\", fg=\"white\")\n",
    "    close_button.grid(row=1, column=0, pady=10)\n",
    "\n",
    "def MyProject():\n",
    "    global l1, drawing_image, predictions, timestamps\n",
    "\n",
    "    # Resize the image to (28, 28)\n",
    "    img_resized = drawing_image.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "    img_resized.save(\"captured_digit.png\")  # Save to inspect the digit\n",
    "\n",
    "    # Convert the image to a grayscale matrix\n",
    "    x = np.asarray(img_resized)\n",
    "    vec = x.flatten().reshape(1, -1)  # Vector of shape (1, 784)\n",
    "\n",
    "    # Normalize the vector\n",
    "    vec_normalized = vec / 255.0\n",
    "\n",
    "    # Load weights\n",
    "    Theta1 = np.loadtxt('Theta1.txt')\n",
    "    Theta2 = np.loadtxt('Theta2.txt')\n",
    "\n",
    "    # Predict the digit\n",
    "    pred = predict(Theta1, Theta2, vec_normalized)\n",
    "    #print(vec_normalized)  # Debugging\n",
    "    \n",
    "    predictions.append(pred[0])\n",
    "    \n",
    "    # Display the result\n",
    "    l1 = Label(window, text=f\"Predicted Digit: {pred}\\n\")\n",
    "    l1.place(x=230, y=420)\n",
    "    show_grayscale_image(img_resized)\n",
    "    \n",
    "    \n",
    "    m = vec_normalized.shape[0]\n",
    "    one_matrix = np.ones((m, 1))\n",
    "    vec_normalized = np.append(one_matrix, vec_normalized, axis=1)  # Add bias unit to first layer\n",
    "    z2 = np.dot(vec_normalized, Theta1.transpose())\n",
    "    a2 = 1 / (1 + np.exp(-z2))  # Sigmoid activation for second layer\n",
    "    one_matrix = np.ones((m, 1))\n",
    "    a2 = np.append(one_matrix, a2, axis=1)  # Add bias unit to hidden layer\n",
    "    z3 = np.dot(a2, Theta2.transpose())\n",
    "    pred_probs = 1 / (1 + np.exp(-z3))  # Sigmoid activation for third layer\n",
    "\n",
    "    # Predict the digit\n",
    "    pred = np.argmax(pred_probs)\n",
    "    predictions.append(pred)\n",
    "    # Show the accuracy table\n",
    "    show_accuracy_table(pred_probs)\n",
    "\n",
    "\n",
    "lastx, lasty = None, None\n",
    "\n",
    "\n",
    "# Clear the canvas and image\n",
    "def clear_widget():\n",
    "    global cv, l1, drawing_image, draw\n",
    "    cv.delete(\"all\")\n",
    "    drawing_image = Image.new(\"L\", (350, 290), \"black\")\n",
    "    draw = ImageDraw.Draw(drawing_image)\n",
    "    l1.destroy()\n",
    "\n",
    "\n",
    "# Activate canvas\n",
    "def event_activation(event):\n",
    "    global lastx, lasty\n",
    "    cv.bind('<B1-Motion>', draw_lines)\n",
    "    lastx, lasty = event.x, event.y\n",
    "\n",
    "\n",
    "# Draw lines on the canvas and update the image\n",
    "def draw_lines(event):\n",
    "    global lastx, lasty, draw\n",
    "    x, y = event.x, event.y\n",
    "    cv.create_line((lastx, lasty, x, y), width=30, fill='white', capstyle=ROUND, smooth=TRUE, splinesteps=12)\n",
    "    draw.line((lastx, lasty, x, y), fill=\"white\", width=30)\n",
    "    lastx, lasty = x, y\n",
    "\n",
    "\n",
    "# Label\n",
    "L1 = Label(window, text=\"Handwritten Digit Recognition\", font=('Algerian', 25), fg=\"blue\")\n",
    "L1.place(x=35, y=10)\n",
    "\n",
    "# Button to clear canvas\n",
    "b1 = Button(window, text=\"1. Clear Canvas\", font=('Algerian', 15), bg=\"blue\", fg=\"white\", command=clear_widget)\n",
    "b1.place(x=120, y=370)\n",
    "\n",
    "# Button to predict digit drawn on canvas\n",
    "b2 = Button(window, text=\"2. Prediction\", font=('Algerian', 15), bg=\"pink\", fg=\"white\", command=MyProject)\n",
    "b2.place(x=320, y=370)\n",
    "\n",
    "# Setting properties of canvas\n",
    "cv = Canvas(window, width=350, height=290, bg='black')\n",
    "cv.place(x=120, y=70)\n",
    "cv.bind('<Button-1>', event_activation)\n",
    "\n",
    "window.geometry(\"600x500\")\n",
    "window.mainloop()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7e42d5da256031c1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T12:38:22.378883Z",
     "start_time": "2024-12-05T12:38:22.377881Z"
    }
   },
   "id": "f04481d292ea199c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
